概述
===

   由于系统不是理想的，因此就存在着网络系统中必须考虑的两个问题————丢包和延时。为了能够实时地排序和输出，就必须引入超时机制来对这两个问题进行很好的处理。</br>
   在真实系统中，所有数据在获得token计算数值时的时间戳就是它真正的发送时间，在发送端缓冲区等待和在网络中传输的时间都应该被算作是它的传输时间。那么设超时机制的时间阈值为Tmax，如果一条数据发出后，经过了Tmax的时间依旧没有被接收系统接收到，那么就可以认为这条数据已经丢了，即使之后再收到这条数据，也认为它是脏数据，不再使用。<br/>
   对本系统来说，有以下几种需要考虑的超时情况（以下称prepare数据为P数据，commit数据为C数据）：
      1、prepare值更大的P数据已经接收到了，超过Tmax时间后再接收到的prepare值更小的P数据认为是脏数据（现实中它已经传输了Tmax+的时间）<br/>
      2、commit值更大的C数据已经接收到了，超过Tmax时间后再接收到的commit值更小的C数据认为是脏数据（同理）<br/>
      3、P数据已经接收到了，经过Tmax+2*maxSleepInterval(millisecond)依旧没有收到它对应的C数据，则认为其C数据已经丢了，成为了脏数据。<br/>

    

算法描述
======

对一组数据对来说
------------
   
   对于一组prepare-commit数据对来说，只有以下四种情况：（）
    
    * P数据和C数据都正确地收到
    * P数据接收到了，C数据没有接收到（包括C数据超时成为脏数据）
    * P数据没有接收到，C数据接收到了（在实际的系统中，真的允许没有prepare只有commit吗？我认为这也是脏数据，不计入统计）
    * P数据和C数据都丢了


对一个信道来说
-------------
    
   如果将接收的过程分隔为(0,Tmax],(Tmax,2Tmax],(3Tmax,4Tmax]......那么P数据对应的C数据不是在本时间范围内，就是在下个时间范围内被接收，如果超过了下个时间范围，那么C数据必然超过了Tmax的接收阈值成为脏数据。</br>
   那么第一个时间间隔(0,Tmax]内的数据存在以下几种情况:
   
    * 互相配对的P数据和C数据
    * 没有配对的P数据===========》C数据如果不在下个时间间隔内，那么C数据就算丢了
    * 没有配对的C数据===========》由于没有上个时间间隔，因此这个C数据一定是P数据丢了的脏数据

   将配对成功的C数据放入一个slice中，命名为Cslice（他们的token都是在第一个时间间隔内获得的）。将没有配对的P数据放入一个map中（golang没有set，为了方便，放入map，value随便设个什么都可以），命名为Pmap.</br>
   
   那么在下一个时间间隔(Tmax,2Tmax]内接收到的数据：
   
    * 互相配对的P数据和C数据
    * 没有配对的P数据=========》等待下个时间间隔去寻觅配对
    * 没有配对的C数据=========》在Pmap中寻觅它的配对，如果找不到，说明它是脏数据
   
   对于互相配对的P-C数据来说，由于P数据接收到的时间比Cslice中的所有数据都要晚，因此这些C数据获得token的时间也一定晚于Cslice里的全部数据，因此它们比Cslice中的所有C数据都要大。<br/>
   将配对成功的C数据放入一个slice中，命名为Cslicenew。现在可以明确的是Cslicenew中的所有C数据是一定比Cslice中的所有数据大的。但是没有配对且不是脏数据的C数据呢？我们无法确认它的token是在上个时间间隔内获得还是这个时间间隔内获得的（但绝对不可能向前超过上个时间间隔，不然无法在Pmap中找到配对）</br>
   我们可以将它们一一遍历，如果它的commit数值比Cslice中的最大值小，那么它的token一定是在上个时间间隔内获得的，于是将它放入Cslice中。如果它的commit数值比Cslice中最大值大，无法确定token的情况，就放入Cslicenew中。此时Cslice中的所有数据仍旧比Cslicenew中的所有数据小，而且可以确定的一点是他们的token都是在第一个时间间隔内获得的，因此他们也一定比未来收到的C数据小（更小的C数据已经超时了）。<br/>
   这样就可以将Cslice排序后输出，作为第一批已判定的最小数据组。然后将Cslicenew替换为Cslice，没有配对的P数据成为新的Pmap。然后继续之后的相同的生成流程<br/>
   
 对多个信道来说
-------------  
   
  由于很难确保多信道的接收时间间隔刚好卡在同一时间戳，因此最好还是利用多个有序数组合并的类似算法，将各个信道的mingroup进行合并而不是每次把多信道的数据取出进行一同比较
